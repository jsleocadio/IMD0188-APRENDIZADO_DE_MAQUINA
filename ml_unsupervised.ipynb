{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dfs_train = {}\n",
    "dfs_val = {}\n",
    "for file in os.listdir(\"vectorized_data\"):\n",
    "    if file.endswith(\"train.csv\"):\n",
    "        df = pd.read_csv(\"vectorized_data/\" + file, index_col=0)\n",
    "        key = file.split(\"_\")[-2]\n",
    "        dfs_train[key] = df\n",
    "    elif file.endswith(\"val.csv\"):\n",
    "        df = pd.read_csv(\"vectorized_data/\" + file, index_col=0)\n",
    "        key = file.split(\"_\")[-2]\n",
    "        dfs_val[key] = df\n",
    "\n",
    "for key in dfs_train:\n",
    "    dfs_train[key] = {\n",
    "        'label': dfs_train[key][\"category1\"],\n",
    "        'data': dfs_train[key].drop(columns=[\"category1\"])\n",
    "    }\n",
    "    \n",
    "    print(f'DFs train {key} (data):{dfs_train[key]['data'].shape}')\n",
    "\n",
    "for key in dfs_val:\n",
    "    dfs_val[key] = {\n",
    "        'label': dfs_val[key][\"category1\"],\n",
    "        'data': dfs_val[key].drop(columns=[\"category1\"])\n",
    "    }\n",
    "    \n",
    "    print(f'DFs validation {key} (data):{dfs_val[key]['data'].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy with k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best vectorizer min_df value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_classification_single(knn, data, data_class):\n",
    "    y_pred = knn.predict(data)\n",
    "    return accuracy_score(data_class, y_pred)\n",
    "\n",
    "def evaluate_classification_dataset(df_train, df_val, n_neighbors):\n",
    "    accuracy_train = []\n",
    "    accuracy_val = []\n",
    "    for k in n_neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "        knn.fit(df_train['data'], df_train['label'])\n",
    "        accuracy_train.append(evaluate_classification_single(knn, df_train['data'], df_train['label']))\n",
    "        accuracy_val.append(evaluate_classification_single(knn, df_val['data'], df_val['label']))\n",
    "    return accuracy_train, accuracy_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [2, 5, 10, 15, 20, 25]\n",
    "# n_neighbors = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "accuracies = {}\n",
    "\n",
    "for key in dfs_train:\n",
    "    print(f'Evaluating dataset {key}')\n",
    "    acc_train, acc_val = evaluate_classification_dataset(dfs_train[key], dfs_val[key], n_neighbors)\n",
    "    accuracies[key] = {\n",
    "        'train': acc_train,\n",
    "        'val': acc_val\n",
    "    }\n",
    "    print(f'--> Accuracy lengths ({key}): \\n {len(acc_train)}\\n {len(acc_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(accuracies, n_neighbors):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for key in accuracies:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(n_neighbors, accuracies[key]['train'], label=f'Train {key}')\n",
    "        plt.xlabel('Number of Neighbors')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Train Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(n_neighbors, accuracies[key]['val'], label=f'Validation {key}')\n",
    "        plt.xlabel('Number of Neighbors')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_accuracy(accuracies, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reduced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the plot, we can see that the best value for min_df is:\n",
    "min_df_val = '0.01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanAbsCorrelation(df):\n",
    "    return df.corr().abs().mean()\n",
    "\n",
    "def selectLowestCorrelationFeatures(df, num_features):\n",
    "    mean_abs_correlation = calculateMeanAbsCorrelation(df)\n",
    "    mean_abs_correlation.sort_values(ascending=True, inplace=True)\n",
    "    mean_abs_correlation = mean_abs_correlation[:num_features]\n",
    "    list_of_features = mean_abs_correlation.index.tolist()\n",
    "    return list_of_features, df[list_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features, df = selectLowestCorrelationFeatures(dfs_train[min_df_val]['data'], 3)\n",
    "print(f'Features: {list_of_features}')\n",
    "dfs_train_corr3 = {\n",
    "    'label': dfs_train[min_df_val]['label'],\n",
    "    'data': df,\n",
    "    'features': list_of_features\n",
    "}\n",
    "\n",
    "list_of_features, df = selectLowestCorrelationFeatures(dfs_train[min_df_val]['data'], 9)\n",
    "print(f'Features: {list_of_features}')\n",
    "dfs_train_corr9 = {\n",
    "    'label': dfs_train[min_df_val]['label'],\n",
    "    'data': df,\n",
    "    'features': list_of_features\n",
    "}\n",
    "\n",
    "dfs_train_corr = {\n",
    "    '3': dfs_train_corr3,\n",
    "    '9': dfs_train_corr9\n",
    "}\n",
    "\n",
    "dfs_val_corr = {\n",
    "    '3': {\n",
    "        'label': dfs_val[min_df_val]['label'],\n",
    "        'data': dfs_val[min_df_val]['data'][dfs_train_corr3['features']]\n",
    "    },\n",
    "    '9': {\n",
    "        'label': dfs_val[min_df_val]['label'],\n",
    "        'data': dfs_val[min_df_val]['data'][dfs_train_corr9['features']]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3, whiten=True).fit(dfs_train[min_df_val]['data'])\n",
    "print(f'PCA components: {pca.n_components_}')\n",
    "dfs_train_pca3 = {\n",
    "    'label': dfs_train[min_df_val]['label'],\n",
    "    'data': pca.transform(dfs_train[min_df_val]['data']),\n",
    "    'pca': pca\n",
    "}\n",
    "\n",
    "pca = PCA(n_components=0.9, whiten=True).fit(dfs_train[min_df_val]['data'])\n",
    "print(f'PCA components: {pca.n_components_}')\n",
    "dfs_train_pca90 = {\n",
    "    'label': dfs_train[min_df_val]['label'],\n",
    "    'data': pca.transform(dfs_train[min_df_val]['data']),\n",
    "    'pca': pca\n",
    "}\n",
    "\n",
    "dfs_train_pca = {\n",
    "    '3': dfs_train_pca3,\n",
    "    '90': dfs_train_pca90\n",
    "}\n",
    "\n",
    "dfs_val_pca = {\n",
    "    '3': {\n",
    "        'label': dfs_val[min_df_val]['label'],\n",
    "        'data': dfs_train_pca3['pca'].transform(dfs_val[min_df_val]['data'])\n",
    "    },\n",
    "    '90': {\n",
    "        'label': dfs_val[min_df_val]['label'],\n",
    "        'data': dfs_train_pca90['pca'].transform(dfs_val[min_df_val]['data'])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the most accurate dataset for each reduction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies_corr = {}\n",
    "# accuracies_pca = {}\n",
    "\n",
    "# n_neighbors = [2, 5, 10, 15, 20, 25]\n",
    "\n",
    "# for key in dfs_train_corr:\n",
    "#     print('Correlation')\n",
    "#     print(f'Evaluating dataset {key}')\n",
    "#     acc_train, acc_val = evaluate_classification_dataset(dfs_train_corr[key], dfs_val_corr[key], n_neighbors)\n",
    "#     accuracies_corr[key] = {\n",
    "#         'train': acc_train,\n",
    "#         'val': acc_val\n",
    "#     }\n",
    "\n",
    "# for key in dfs_train_pca:\n",
    "#     print('PCA')\n",
    "#     print(f'Evaluating dataset {key}')\n",
    "#     acc_train, acc_val = evaluate_classification_dataset(dfs_train_pca[key], dfs_val_pca[key], n_neighbors)\n",
    "#     accuracies_pca[key] = {\n",
    "#         'train': acc_train,\n",
    "#         'val': acc_val\n",
    "#     }\n",
    "#     print(f'--> Accuracy lengths ({key}): \\n {len(acc_train)}\\n {len(acc_val)}')\n",
    "\n",
    "# plot_accuracy(accuracies_corr, n_neighbors)\n",
    "# plot_accuracy(accuracies_pca, n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dfs_train = {\n",
    "    'corr' : dfs_train_corr['3'],\n",
    "    'pca' : dfs_train_pca['90'],\n",
    "}\n",
    "\n",
    "best_dfs_val = {\n",
    "    'corr' : dfs_val_corr['3'],\n",
    "    'pca' : dfs_val_pca['90'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import davies_bouldin_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_performance_single(data_train, data_test, labels, k, method):\n",
    "  trained = method(data_train, k)\n",
    "\n",
    "  y_pred = trained.fit_predict(data_test)\n",
    "\n",
    "  return [davies_bouldin_score(data_test, y_pred), silhouette_score(data_test, y_pred, metric='cosine'), adjusted_rand_score(labels, y_pred)]\n",
    "\n",
    "def evaluate_performance_method(dbs_train, dbs_val, labels, nclusters, method, dbs_names=[]):\n",
    "  metrics = []\n",
    "  i = 0\n",
    "  len_dbs = len(dbs_train)\n",
    "  for i in range(len_dbs):\n",
    "    metrics_for_db = []\n",
    "    for k in nclusters:\n",
    "      metrics_for_db.append(evaluate_performance_single(dbs_train[i], dbs_val[i], labels[i], k, method))\n",
    "    # print(metrics_for_db)\n",
    "    metrics_for_db = list(zip(*metrics_for_db))\n",
    "    # print(metrics_for_db)\n",
    "    if dbs_names:\n",
    "      metrics.append([dbs_names[i], metrics_for_db])\n",
    "    else:\n",
    "      metrics.append([f'db{i}', metrics_for_db])\n",
    "    i += 1\n",
    "  return metrics\n",
    "\n",
    "def plot_results(results, number_clusters):\n",
    "  fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "  for i in range(len(results)):\n",
    "    axs[0].plot(number_clusters, results[i][1][0], label=results[i][0])\n",
    "  axs[0].set_xlim(number_clusters[0], number_clusters[-1])\n",
    "  axs[0].legend()\n",
    "  axs[0].set_xlabel('k')\n",
    "  axs[0].set_ylabel('Davies-Bouldin Score')\n",
    "\n",
    "  for i in range(len(results)):\n",
    "    axs[1].plot(number_clusters, results[i][1][1], label=results[i][0])\n",
    "  axs[1].set_xlim(number_clusters[0], number_clusters[-1])\n",
    "  axs[1].legend()\n",
    "  axs[1].set_xlabel('k')\n",
    "  axs[1].set_ylabel('Silhouette Score')\n",
    "\n",
    "  for i in range(len(results)):\n",
    "    axs[2].plot(number_clusters, results[i][1][2], label=results[i][0])\n",
    "  axs[2].set_xlim(number_clusters[0], number_clusters[-1])\n",
    "  axs[2].legend()\n",
    "  axs[2].set_xlabel('k')\n",
    "  axs[2].set_ylabel('Adjusted Rand Score')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(dataset, n_clusters):\n",
    "  from sklearn.cluster import KMeans\n",
    "\n",
    "  kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=300, max_iter=10, random_state=37)\n",
    "\n",
    "  kmeans.fit(dataset)\n",
    "\n",
    "  return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = [2, 5, 10, 15, 20, 25]\n",
    "kmeans_results = evaluate_performance_method(\n",
    "        [best_dfs_train['corr']['data'], best_dfs_train['pca']['data']],\n",
    "        [best_dfs_val['corr']['data'], best_dfs_val['pca']['data']],\n",
    "        [best_dfs_val['corr']['label'], best_dfs_val['pca']['label']],\n",
    "        number_clusters,\n",
    "        kmeans,\n",
    "        dbs_names=['Correlation', 'PCA']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(kmeans_results, number_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glpi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
